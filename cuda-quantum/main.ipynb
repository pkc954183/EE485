{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rWBWdOsywn7M"
      },
      "outputs": [],
      "source": [
        "!pip install cudaq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b-_vjLFuwn7O"
      },
      "outputs": [],
      "source": [
        "import cudaq\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "my_api_key=\"M4slkdiWJVa28kQONDktWYcvIqoV1Trh\"\n",
        "#api_key = os.getenv('IONQ_API_KEY') or getpass('Enter your IonQ API key: ')\n",
        "os.environ['IONQ_API_KEY'] = my_api_key  # Remove when set_target takes api_key\n",
        "cudaq.set_target('ionq', qpu='simulator')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xyov3eVRwn7O",
        "outputId": "b9e15cfa-95d0-4236-9a52-c66314af0bd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{ 00:500 11:500 }\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define the kernel and allocate two qubits\n",
        "kernel = cudaq.make_kernel()\n",
        "qubits = kernel.qalloc(2)\n",
        "\n",
        "# Apply a Hadamard gate to the first qubit\n",
        "kernel.h(qubits[0])\n",
        "\n",
        "# Apply a CX gate from the first to second qubit\n",
        "kernel.cx(qubits[0], qubits[1])\n",
        "\n",
        "# Execute the kernel on the computer and print the result\n",
        "print(cudaq.sample(kernel))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cudaq\n",
        "\n",
        "# Define a circuit (CUDA-Q kernel)\n",
        "@cudaq.kernel\n",
        "def hello_world():\n",
        "    qubits = cudaq.qvector(2)\n",
        "    h(qubits[0])\n",
        "    x.ctrl(qubits[0], qubits[1])\n",
        "\n",
        "# Set the target to IonQ's simulator\n",
        "cudaq.set_target('ionq', noise)\n",
        "\n",
        "# Run the circuit and print results\n",
        "result = cudaq.sample(hello_world)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56R2HSYF0lYz",
        "outputId": "4d5b5c10-c6d4-49eb-e30c-3f0d86941517"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{ 00:500 11:500 }\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cudaq\n",
        "\n",
        "# Define a circuit (CUDA-Q kernel)\n",
        "@cudaq.kernel\n",
        "def hello_qpu():\n",
        "    qubits = cudaq.qvector(2)\n",
        "    h(qubits[0])\n",
        "    x.ctrl(qubits[0], qubits[1])\n",
        "\n",
        "# Set the target to IonQ Aria 1\n",
        "cudaq.set_target('ionq', qpu='qpu.aria-1')\n",
        "\n",
        "# Submit the circuit\n",
        "async_result = cudaq.sample_async(hello_qpu, shots_count=1000)\n",
        "\n",
        "# Save the job information to a file\n",
        "with open(\"hello_qpu.txt\", \"w\") as file:\n",
        "    file.write(str(async_result))"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mCIjXi_1EAz",
        "outputId": "46d5c666-f0e1-48d6-a9a1-21afb6a1810c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RuntimeError: HTTP POST Error - status code 400: : {\"error\":\"Bad Request\",\"message\":\"Unable to run jobs on IonQ Aria. Please visit our Quantum Cloud Page https://ionq.com/quantum-cloud to learn more about getting access to our IonQ Aria.\",\"statusCode\":400}\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'RuntimeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AssertionError\n",
            "RuntimeError: HTTP POST Error - status code 400: : {\"error\":\"Bad Request\",\"message\":\"Unable to run jobs on IonQ Aria. Please visit our Quantum Cloud Page https://ionq.com/quantum-cloud to learn more about getting access to our IonQ Aria.\",\"statusCode\":400}\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'RuntimeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AssertionError\n",
            "RuntimeError: HTTP POST Error - status code 400: : {\"error\":\"Bad Request\",\"message\":\"Unable to run jobs on IonQ Aria. Please visit our Quantum Cloud Page https://ionq.com/quantum-cloud to learn more about getting access to our IonQ Aria.\",\"statusCode\":400}\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'RuntimeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AssertionError\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$[1,2,3,4] \\rightarrow [1,2,5,6] \\rightarrow [1,3,5,7] $$\n",
        "\n",
        "$$[1,2,3,4,5,6,7,8] \\rightarrow [1,2,3,4,9,10,11,12] \\rightarrow [1,2,5,6,9,10,13,14] \\rightarrow [1,3,5,7,9,11,13,15] $$"
      ],
      "metadata": {
        "id": "-XQG9Sb3PJd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cudaq\n",
        "from cudaq import spin\n",
        "from typing import List\n",
        "\n",
        "# We'll use the graph below to illustrate how QAOA can be used to\n",
        "# solve a max cut problem\n",
        "\n",
        "#       v1  0--------------0 v2\n",
        "#           |              | \\\n",
        "#           |              |  \\\n",
        "#           |              |   \\\n",
        "#           |              |    \\\n",
        "#       v0  0--------------0 v3-- 0 v4\n",
        "# The max cut solutions are 01011, 10100, 01010, 10101 .\n",
        "\n",
        "# First we define the graph nodes (i.e., vertices) and edges as lists of integers so that they can be broadcast into\n",
        "# a cudaq.kernel.\n",
        "nodes: List[int] = [0, 1, 2, 3] # [0, 1, 2, 3, 4]\n",
        "edges = [[0, 1], [1, 2], [2, 3], [3, 0], [2, 4], [3, 4]]\n",
        "edges_src: List[int] = [edges[i][0] for i in range(len(edges))]\n",
        "edges_tgt: List[int] = [edges[i][1] for i in range(len(edges))]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "jgXSa6-u1bY1",
        "outputId": "78c2052b-d029-4b21-ef5d-c6e117b3e2cf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'cudaq'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-664977229.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcudaq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcudaq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cudaq'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem parameters\n",
        "# The number of qubits we'll need is the same as the number of vertices in our graph\n",
        "qubit_count: int = len(nodes)\n",
        "\n",
        "# We can set the layer count to be any positive integer.  Larger values will create deeper circuits\n",
        "layer_count: int = 1 #2\n",
        "\n",
        "# Each layer of the QAOA kernel contains 2 parameters\n",
        "parameter_count: int = 2 * layer_count\n",
        "\n",
        "\n",
        "@cudaq.kernel\n",
        "def qaoaProblem(qubit_0: cudaq.qubit, qubit_1: cudaq.qubit, alpha: float):\n",
        "    \"\"\"Build the QAOA gate sequence between two qubits that represent an edge of the graph\n",
        "    Parameters\n",
        "    ----------\n",
        "    qubit_0: cudaq.qubit\n",
        "        Qubit representing the first vertex of an edge\n",
        "    qubit_1: cudaq.qubit\n",
        "        Qubit representing the second vertex of an edge\n",
        "    thetas: List[float]\n",
        "        Free variable\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    cudaq.Kernel\n",
        "        Subcircuit of the problem kernel for Max-Cut of the graph with a given edge\n",
        "    \"\"\"\n",
        "    # x.ctrl(qubit_0, qubit_1)\n",
        "    # rz(2.0 * alpha, qubit_1)\n",
        "    # x.ctrl(qubit_0, qubit_1)\n",
        "\n",
        "    # Reconfiguration Beam Splitter Ansatz\n",
        "    h(qubit_0)\n",
        "    h(qubit_1)\n",
        "    x.ctrl(qubit_0, qubit_1)\n",
        "    ry(2.0 * alpha, qubit_0)\n",
        "    ry(2.0 * alpha, qubit_1)\n",
        "    x.ctrl(qubit_0, qubit_1)\n",
        "    h(qubit_0)\n",
        "    h(qubit_1)\n",
        "\n",
        "\n",
        "# We now define the kernel_qaoa function which will be the QAOA circuit for our graph\n",
        "# Since the QAOA circuit for max cut depends on the structure of the graph,\n",
        "# we'll feed in global concrete variable values into the kernel_qaoa function for the qubit_count, layer_count, edges_src, edges_tgt.\n",
        "# The types for these variables are restricted to Quake Values (e.g. qubit, int, List[int], ...)\n",
        "# The thetas plaeholder will be our free parameters\n",
        "@cudaq.kernel\n",
        "def kernel_qaoa(qubit_count: int, layer_count: int, edges_src: List[int],\n",
        "                edges_tgt: List[int], thetas: List[float]):\n",
        "    \"\"\"Build the QAOA circuit for max cut of the graph with given edges and nodes\n",
        "    Parameters\n",
        "    ----------\n",
        "    qubit_count: int\n",
        "        Number of qubits in the circuit, which is the same as the number of nodes in our graph\n",
        "    layer_count : int\n",
        "        Number of layers in the QAOA kernel\n",
        "    edges_src: List[int]\n",
        "        List of the first (source) node listed in each edge of the graph, when the edges of the graph are listed as pairs of nodes\n",
        "    edges_tgt: List[int]\n",
        "        List of the second (target) node listed in each edge of the graph, when the edges of the graph are listed as pairs of nodes\n",
        "    thetas: List[float]\n",
        "        Free variables to be optimized\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    cudaq.Kernel\n",
        "        QAOA circuit for Max-Cut for max cut of the graph with given edges and nodes\n",
        "    \"\"\"\n",
        "    # Let's allocate the qubits\n",
        "    qreg = cudaq.qvector(qubit_count)\n",
        "    # And then place the qubits in superposition\n",
        "    h(qreg)\n",
        "\n",
        "    # Each layer has two components: the problem kernel and the mixer\n",
        "    for i in range(layer_count):\n",
        "        # QAOA Ansatz - Add the problem kernel to each layer\n",
        "        # for edge in range(len(edges_src)):\n",
        "        #     qubitu = edges_src[edge]\n",
        "        #     qubitv = edges_tgt[edge]\n",
        "        #     qaoaProblem(qreg[qubitu], qreg[qubitv], thetas[i])\n",
        "\n",
        "        # Butterfly Ansatz (Assuming len(nodes) = 2^k = len_qubit)\n",
        "        target_qubit_list = [i for i in range(int(len(nodes)/2))]\n",
        "        len_node_log2 = int(np.log2(len(nodes)))\n",
        "        for j in range(len_node_log2-1,-1,-1):\n",
        "            for target_qubit in target_qubit_list:\n",
        "                qaoaProblem(qreg[target_qubit], qreg[target_qubit + 2**j], thetas[i])\n",
        "\n",
        "            # update target_qubit_list\n",
        "            # j = len_node_log2-1 -> k = 0\n",
        "            for k in range(2**(len_node_log2-j-1)):\n",
        "                anti_position = 2*k\n",
        "                position = len(nodes) - anti_position\n",
        "                for l in range(2**j):\n",
        "                    ind = k+l\n",
        "                    target_qubit_list[k+l] = target_qubit_list[i] + 2**j\n",
        "\n",
        "\n",
        "        # Add the mixer kernel to each layer\n",
        "        for j in range(qubit_count):\n",
        "            rx(2.0 * thetas[i + layer_count], qreg[j])"
      ],
      "metadata": {
        "id": "X7_b1DKG4pNL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "nlo_bkw8VX7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(cudaq.draw(kernel_qaoa(qubit_count, layer_count, edges_src, edges_tgt, [0.0, 0.0])))"
      ],
      "metadata": {
        "id": "lyEY4jhUVXCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$[1,2,3,4] \\rightarrow [1,2,5,6] \\rightarrow [1,3,5,7] $$\n",
        "\n",
        "$$[1,2,3,4,5,6,7,8] \\rightarrow [1,2,3,4,9,10,11,12] \\rightarrow [1,2,5,6,9,10,13,14] \\rightarrow [1,3,5,7,9,11,13,15] $$"
      ],
      "metadata": {
        "id": "dQ4Nlsf-QSY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(range(5,-1,-1))"
      ],
      "metadata": {
        "id": "0YVAO6aDRVsB",
        "outputId": "4156e336-aceb-4ad4-ae06-64269cb0edd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 4, 3, 2, 1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The problem Hamiltonian\n",
        "# Define a function to generate the Hamiltonian for a max cut problem using the graph\n",
        "# with the given edges\n",
        "\n",
        "\n",
        "def hamiltonian_max_cut(edges_src, edges_tgt):\n",
        "    \"\"\"Hamiltonian for finding the max cut for the graph with given edges and nodes\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    edges_src: List[int]\n",
        "        List of the first (source) node listed in each edge of the graph, when the edges of the graph are listed as pairs of nodes\n",
        "    edges_tgt: List[int]\n",
        "        List of the second (target) node listed in each edge of the graph, when the edges of the graph are listed as pairs of nodes\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    cudaq.SpinOperator\n",
        "        Hamiltonian for finding the max cut of the graph with given edges\n",
        "    \"\"\"\n",
        "\n",
        "    hamiltonian = 0\n",
        "\n",
        "    for edge in range(len(edges_src)):\n",
        "\n",
        "        qubitu = edges_src[edge]\n",
        "        qubitv = edges_tgt[edge]\n",
        "        # Add a term to the Hamiltonian for the edge (u,v)\n",
        "        hamiltonian += 0.5 * (spin.z(qubitu) * spin.z(qubitv) -\n",
        "                              spin.i(qubitu) * spin.i(qubitv))\n",
        "\n",
        "    return hamiltonian"
      ],
      "metadata": {
        "id": "rCcK8BkS5O7S"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the optimizer and its initial parameters.\n",
        "cudaq.set_random_seed(13)\n",
        "optimizer = cudaq.optimizers.NelderMead()\n",
        "np.random.seed(13)\n",
        "optimizer.initial_parameters = np.random.uniform(-np.pi / 8, np.pi / 8,\n",
        "                                                 parameter_count)\n",
        "print(\"Initial parameters = \", optimizer.initial_parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUxr9OVl5UD-",
        "outputId": "feb49d9b-5aec-43a0-9003-e83c3d7e501c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial parameters =  [0.21810696323572243, -0.20613464375211488]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cudaq.set_target('nvidia')\n",
        "cudaq.set_target('qpp-cpu')\n",
        "# cudaq.set_target('ionq') # 실제 작동함\n",
        "\n",
        "# Generate the Hamiltonian for our graph\n",
        "hamiltonian = hamiltonian_max_cut(edges_src, edges_tgt)\n",
        "print(hamiltonian)\n",
        "\n",
        "# Define the objective, return `<state(params) | H | state(params)>`\n",
        "# Note that in the `observe` call we list the kernel, the hamiltonian, and then the concrete global variable values of our kernel\n",
        "# followed by the parameters to be optimized.\n",
        "\n",
        "\n",
        "\n",
        "def objective(parameters):\n",
        "#    cnt_kunkuk += 1\n",
        "    print(\"hello world\")\n",
        "    return cudaq.observe(kernel_qaoa, hamiltonian, qubit_count, layer_count,\n",
        "                         edges_src, edges_tgt, parameters).expectation()\n",
        "\n",
        "\n",
        "# Optimize!\n",
        "optimal_expectation, optimal_parameters = optimizer.optimize(\n",
        "    dimensions=parameter_count, function=objective)\n",
        "\n",
        "# Alternatively we can use the vqe call (just comment out the above code and uncomment the code below)\n",
        "# optimal_expectation, optimal_parameters = cudaq.vqe(\n",
        "#    kernel=kernel_qaoa,\n",
        "#    spin_operator=hamiltonian,\n",
        "#    argument_mapper=lambda parameter_vector: (qubit_count, layer_count, edges_src, edges_tgt, parameter_vector),\n",
        "#    optimizer=optimizer,\n",
        "#    parameter_count=parameter_count)\n",
        "\n",
        "print('optimal_expectation =', optimal_expectation)\n",
        "print('Therefore, the max cut value is at least ', -1 * optimal_expectation)\n",
        "print('optimal_parameters =', optimal_parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uefbVo9Q5Wuz",
        "outputId": "c3887916-e709-4c4d-fae0-9b66cb3501ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0.5+0i) * Z0Z1 + (-0.5+0i) * I0I1 + (0+0i) + (0.5+0i) * Z1Z2 + (-0.5+0i) * I1I2 + (0.5+0i) * Z2Z3 + (-0.5+0i) * I2I3 + (0.5+0i) * Z0Z3 + (-0.5+0i) * I0I3 + (0.5+0i) * Z2Z4 + (-0.5+0i) * I2I4 + (0.5+0i) * Z3Z4 + (-0.5+0i) * I3I4\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello world\n",
            "RuntimeError: NLOpt runtime error: nlopt failure\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'RuntimeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AssertionError\n",
            "RuntimeError: NLOpt runtime error: nlopt failure\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'RuntimeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AssertionError\n",
            "RuntimeError: NLOpt runtime error: nlopt failure\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'RuntimeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AssertionError\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample the circuit using the optimized parameters\n",
        "# Since our kernel has more than one argument, we need to list the values for each of these variables in order in the `sample` call.\n",
        "counts = cudaq.sample(kernel_qaoa, qubit_count, layer_count, edges_src,\n",
        "                      edges_tgt, optimal_parameters)\n",
        "print(counts)\n",
        "\n",
        "# Identify the most likely outcome from the sample\n",
        "max_cut = max(counts, key=lambda x: counts[x])\n",
        "print('The max cut is given by the partition: ',\n",
        "      max(counts, key=lambda x: counts[x]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWJ1pHiY5j0H",
        "outputId": "c8332ca7-a4ef-4d94-f0fc-18b6952e8a6b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{ 00000:1 00010:2 00011:3 00100:3 00101:2 00110:54 00111:10 01000:3 01001:41 01010:148 01011:154 01100:8 01101:2 01110:47 01111:2 10000:5 10001:65 10010:7 10011:7 10100:144 10101:165 10110:40 10111:3 11000:7 11001:59 11010:2 11011:3 11100:7 11101:1 11110:1 11111:4 }\n",
            "\n",
            "The max cut is given by the partition:  10101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4e2FWaGheYPc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}